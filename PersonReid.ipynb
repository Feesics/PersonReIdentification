{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torchreid import data_manager\n",
    "from torchreid.dataset_loader import ImageDataset\n",
    "from torchreid import transforms as T\n",
    "from torchreid import models\n",
    "from torchreid.losses import CrossEntropyLabelSmooth, DeepSupervision\n",
    "from torchreid.utils.iotools import save_checkpoint, check_isfile\n",
    "from torchreid.utils.avgmeter import AverageMeter\n",
    "from torchreid.utils.logger import Logger\n",
    "from torchreid.utils.torchtools import set_bn_to_eval, count_num_param\n",
    "from torchreid.utils.reidtools import visualize_ranked_results\n",
    "from torchreid.eval_metrics import evaluate\n",
    "from torchreid.optimizers import init_optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"data/market1501/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Market1501 loaded\n",
      "Dataset statistics:\n",
      "  ------------------------------\n",
      "  subset   | # ids | # images\n",
      "  ------------------------------\n",
      "  train    |   751 |    12936\n",
      "  query    |   750 |     3368\n",
      "  gallery  |   751 |    15913\n",
      "  ------------------------------\n",
      "  total    |  1501 |    32217\n",
      "  ------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = data_manager.init_imgreid_dataset(root='data', name='market1501', split_id='0',\n",
    "cuhk03_labeled=False, cuhk03_classic_split=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    Random2DTranslation(height, width),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = T.Compose([\n",
    "    T.Resize((height, width)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    ImageDataset(dataset.train, transform=transform_train),\n",
    "    batch_size = 64, shuffle = True, num_workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryloader = DataLoader(\n",
    "    ImageDataset(dataset.query, transform=transform_test),\n",
    "    batch_size = 64, shuffle = False, num_workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "galleryloader = DataLoader(\n",
    "    ImageDataset(dataset.gallery, transform=transform_test),\n",
    "    batch_size=64, shuffle=False, num_workers= 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, loss={'xent'}, **kwargs):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.loss = loss\n",
    "        resnet50 = torchvision.models.resnet50(pretraine.Sequential(*list(resnet50.childred=True)\n",
    "        self.base = nnn())[:-2])\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "        self.feat_dim = 2048\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        f = x.view(x.size(0), -1)\n",
    "        if not self.training:\n",
    "            return f\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        if self.loss == {'xent'}:\n",
    "            return y\n",
    "        elif self.loss == {'xent', 'htri'}:\n",
    "            return y, f\n",
    "        else:\n",
    "            raise KeyError(\"Unsupported loss: {}\".format(self.loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, criterion, optimizer, trainloader, use_gpu, freeze_bn=False):\n",
    "    losses = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    if freeze_bn:\n",
    "        model.apply(set_bn_to_eval)\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (imgs, pids, _) in enumerate(trainloader):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        if use_gpu:\n",
    "            imgs, pids = imgs.cuda(), pids.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        if isinstance(outputs, tuple):\n",
    "            loss = DeepSupervision(criterion, outputs, pids)\n",
    "        else:\n",
    "            loss = criterion(outputs, pids)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        losses.update(loss.item(), pids.size(0))\n",
    "\n",
    "        if (batch_idx + 1) % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.4f} ({data_time.avg:.4f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch + 1, batch_idx + 1, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "        \n",
    "        end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.init_model(name='resnet50', num_classes=dataset.num_train_pids, loss={'xent'}, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][10/203]\tTime 0.664 (0.702)\tData 0.0059 (0.0391)\tLoss 6.5524 (6.9091)\t\n",
      "Epoch: [1][20/203]\tTime 0.664 (0.682)\tData 0.0062 (0.0227)\tLoss 6.5005 (6.8297)\t\n",
      "Epoch: [1][30/203]\tTime 0.659 (0.675)\tData 0.0062 (0.0172)\tLoss 6.7040 (6.7659)\t\n",
      "Epoch: [1][40/203]\tTime 0.659 (0.671)\tData 0.0061 (0.0144)\tLoss 6.7379 (6.7235)\t\n",
      "Epoch: [1][50/203]\tTime 0.662 (0.669)\tData 0.0065 (0.0127)\tLoss 6.4561 (6.6886)\t\n",
      "Epoch: [1][60/203]\tTime 0.663 (0.667)\tData 0.0065 (0.0116)\tLoss 6.3843 (6.6584)\t\n",
      "Epoch: [1][70/203]\tTime 0.660 (0.667)\tData 0.0060 (0.0108)\tLoss 6.4481 (6.6340)\t\n",
      "Epoch: [1][80/203]\tTime 0.664 (0.666)\tData 0.0063 (0.0103)\tLoss 6.4512 (6.6099)\t\n",
      "Epoch: [1][90/203]\tTime 0.663 (0.666)\tData 0.0058 (0.0098)\tLoss 6.3704 (6.5882)\t\n",
      "Epoch: [1][100/203]\tTime 0.660 (0.665)\tData 0.0055 (0.0094)\tLoss 6.3028 (6.5665)\t\n",
      "Epoch: [1][110/203]\tTime 0.660 (0.665)\tData 0.0063 (0.0091)\tLoss 6.3785 (6.5441)\t\n",
      "Epoch: [1][120/203]\tTime 0.663 (0.665)\tData 0.0061 (0.0089)\tLoss 6.1427 (6.5186)\t\n",
      "Epoch: [1][130/203]\tTime 0.659 (0.664)\tData 0.0060 (0.0087)\tLoss 6.0118 (6.4985)\t\n",
      "Epoch: [1][140/203]\tTime 0.658 (0.664)\tData 0.0061 (0.0085)\tLoss 6.0579 (6.4768)\t\n",
      "Epoch: [1][150/203]\tTime 0.666 (0.664)\tData 0.0065 (0.0083)\tLoss 6.0082 (6.4572)\t\n",
      "Epoch: [1][160/203]\tTime 0.664 (0.664)\tData 0.0066 (0.0082)\tLoss 6.2126 (6.4353)\t\n",
      "Epoch: [1][170/203]\tTime 0.656 (0.664)\tData 0.0061 (0.0081)\tLoss 6.0913 (6.4157)\t\n",
      "Epoch: [1][180/203]\tTime 0.657 (0.663)\tData 0.0058 (0.0080)\tLoss 6.1731 (6.3984)\t\n",
      "Epoch: [1][190/203]\tTime 0.661 (0.663)\tData 0.0059 (0.0079)\tLoss 6.0839 (6.3770)\t\n",
      "Epoch: [1][200/203]\tTime 0.657 (0.663)\tData 0.0069 (0.0078)\tLoss 5.7117 (6.3555)\t\n",
      "Epoch: [2][10/203]\tTime 0.662 (0.697)\tData 0.0059 (0.0432)\tLoss 5.7799 (5.6811)\t\n",
      "Epoch: [2][20/203]\tTime 0.658 (0.678)\tData 0.0065 (0.0248)\tLoss 5.9506 (5.7202)\t\n",
      "Epoch: [2][30/203]\tTime 0.660 (0.672)\tData 0.0061 (0.0186)\tLoss 5.6625 (5.7118)\t\n",
      "Epoch: [2][40/203]\tTime 0.660 (0.669)\tData 0.0063 (0.0155)\tLoss 5.4435 (5.6889)\t\n",
      "Epoch: [2][50/203]\tTime 0.663 (0.668)\tData 0.0062 (0.0136)\tLoss 5.3414 (5.6561)\t\n",
      "Epoch: [2][60/203]\tTime 0.664 (0.667)\tData 0.0059 (0.0124)\tLoss 5.4997 (5.6192)\t\n",
      "Epoch: [2][70/203]\tTime 0.663 (0.666)\tData 0.0061 (0.0115)\tLoss 5.3391 (5.5959)\t\n",
      "Epoch: [2][80/203]\tTime 0.661 (0.666)\tData 0.0060 (0.0108)\tLoss 5.4100 (5.5775)\t\n",
      "Epoch: [2][90/203]\tTime 0.666 (0.665)\tData 0.0061 (0.0103)\tLoss 5.4427 (5.5621)\t\n",
      "Epoch: [2][100/203]\tTime 0.662 (0.665)\tData 0.0055 (0.0098)\tLoss 5.1656 (5.5458)\t\n",
      "Epoch: [2][110/203]\tTime 0.666 (0.665)\tData 0.0064 (0.0095)\tLoss 5.3284 (5.5188)\t\n",
      "Epoch: [2][120/203]\tTime 0.660 (0.664)\tData 0.0061 (0.0092)\tLoss 5.2277 (5.5016)\t\n",
      "Epoch: [2][130/203]\tTime 0.667 (0.664)\tData 0.0065 (0.0090)\tLoss 5.2270 (5.4759)\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,10):\n",
    "    train(epoch, model, criterion, optimizer, trainloader=trainloader, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
